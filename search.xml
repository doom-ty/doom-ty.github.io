<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux常用命令笔记]]></title>
    <url>%2F2019%2F03%2F19%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1、释放cache缓存1echo 3 &gt; /proc/sys/vm/drop_caches]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java异常处理及日志规范]]></title>
    <url>%2F2019%2F03%2F12%2F%E6%97%A5%E5%BF%97%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[一、日志级别. info：记录的重要信息. warn：警告信息. error：系统运行错误. debug：debug信息. trace：比debug更详细的跟踪信息一般开发中比较常用的为info、warn和error 二、规范详情 【强制】不要在catch中使用printStackTrace() 【强制】不要在记录完日之后再次抛出异常，否则会记录两次错误信息反例：1234try&#123;...&#125; catch(Exception e) &#123; log.err("errorInfo &#123;&#125;", obj, e); throw new MyException();&#125; 以下内容摘自《阿里巴巴java开发规范手册》 （一）异常处理 【强制】Java 类库中定义的可以通过预检查方式规避的 RuntimeException 异常不应该通过catch 的方式来处理，比如： NullPointerException ， IndexOutOfBoundsException 等等。 说明：无法通过预检查的异常除外，比如，在解析字符串形式的数字时，不得不通过 catchNumberFormatException 来实现。 正例： 1if (obj != null) &#123;...&#125; 反例： 1try &#123; obj.method(); &#125; catch (NullPointerException e) &#123;…&#125; 【强制】异常不要用来做流程控制，条件控制。 说明：异常设计的初衷是解决程序运行中的各种意外情况，且异常的处理效率比条件判断方式要低很多。 【强制】 catch 时请分清稳定代码和非稳定代码，稳定代码指的是无论如何不会出错的代码。对于非稳定代码的 catch 尽可能进行区分异常类型，再做对应的异常处理。 说明：对大段代码进行 try - catch ，使程序无法根据不同的异常做出正确的应激反应，也不利于定位问题，这是一种不负责任的表现。 正例：用户注册的场景中，如果用户输入非法字符，或用户名称已存在，或用户输入密码过于简单，在程序上作出分门别类的判断，并提示给用户。 【强制】捕获异常是为了处理它，不要捕获了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者。最外层的业务使用者，必须处理异常，将其转化为用户可以理解的内容。 【强制】有 try 块放到了事务代码中， catch 异常后，如果需要回滚事务，一定要注意手动回滚事务。 【强制】 finally 块必须对资源对象、流对象进行关闭，有异常也要做 try - catch 。 说明：如果 JDK 7 及以上，可以使用 try - with - resources 方式。 【强制】不要在 finally 块中使用 return 。 说明： finally 块中的 return 返回后方法结束执行，不会再执行 try 块中的 return 语句。 【强制】捕获异常与抛异常，必须是完全匹配，或者捕获异常是抛异常的父类。 说明：如果预期对方抛的是绣球，实际接到的是铅球，就会产生意外情况。 【推荐】方法的返回值可以为 null ，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回 null 值。 说明：本手册明确防止 NPE 是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回null 的情况。 【推荐】防止 NPE ，是程序员的基本修养，注意 NPE 产生的场景：1） 返回类型为基本数据类型， return 包装数据类型的对象时，自动拆箱有可能产生 NPE 。 反例： public int f() { return Integer 对象}， 如果为 null ，自动解箱抛 NPE 。2 ） 数据库的查询结果可能为 null 。3 ） 集合里的元素即使 isNotEmpty ，取出的数据元素也可能为 null 。4 ） 远程调用返回对象时，一律要求进行空指针判断，防止 NPE 。5 ） 对于 Session 中获取的数据，建议 NPE 检查，避免空指针。6 ） 级联调用 obj.getA().getB().getC()； 一连串调用，易产生 NPE 。 正例：使用 JDK8 的 Optional 类来防止 NPE 问题。 【推荐】定义时区分 unchecked / checked 异常，避免直接抛出 new RuntimeException() ，更不允许抛出 Exception 或者 Throwable ，应使用有业务含义的自定义异常。推荐业界已定义过的自定义异常，如： DAOException / ServiceException 等。 【参考】对于公司外的 http / api 开放接口必须使用“错误码” ； 而应用内部推荐异常抛出；跨应用间 RPC 调用优先考虑使用 Result 方式，封装 isSuccess()方法 、“错误码”、“错误简短信息”。说明：关于 RPC 方法返回方式使用 Result 方式的理由：1 ） 使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。2 ） 如果不加栈信息，只是 new 自定义异常，加入自己的理解的 error message ，对于调用端解决问题的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。 【参考】避免出现重复的代码 （Don ’ t Repeat Yourself） ，即 DRY 原则。说明：随意复制和粘贴代码，必然会导致代码的重复，在以后需要修改时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。正例：一个类中有多个 public 方法，都需要进行数行相同的参数校验操作，这个时候请抽取：1private boolean checkParam(DTO dto) &#123;...&#125; ( 二 ) 日志规约 【强制】应用中不可直接使用日志系统（Log4j、Logback）中的API ，而应依赖使用日志框架SLF4J中的API ，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。 123import org.slf4j.Logger;import org.slf4j.LoggerFactory;private static final Logger logger = LoggerFactory.getLogger(Abc.class); 【强制】日志文件至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。 【强制】应用中的扩展日志 （ 如打点、临时监控、访问日志等 ） 命名方式： appName_logType_logName.log 。 logType :日志类型，如 stats / monitor / access 等 ；logName :日志描述。 这种命名的好处： 通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查找。 正例： mppserver 应用中单独监控时区转换异常，如： mppserver _ monitor _ timeZoneConvert . log 说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系统进行及时监控。 【强制】对 trace / debug / info 级别的日志输出，必须使用条件输出形式或者使用占位符的方式。 说明： 1logger.debug("Processing trade with id:" + id + "and symbol:" + symbol); 如果日志级别是 warn ，上述日志不会打印，但是会执行字符串拼接操作，如果 symbol 是对象，会执行 toString() 方法，浪费了系统资源，执行了上述操作，最终日志却没有打印。 正例：（ 条件 ）建设采用如下方式 123if (logger.isDebugEnabled()) &#123; logger.debug("Processing trade with id: " + id + " and symbol: " + symbol);&#125; 正例：（ 占位符 ） 1logger.debug("Processing trade with id: &#123;&#125; and symbol : &#123;&#125; ", id, symbol); 【强制】避免重复打印日志，浪费磁盘空间，务必在 log 4 j . xml 中设置 additivityfalse 。 正例： 1&lt;logger name="com.taobao.dubbo.config" additivity="false"&gt; 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过关键字 throws 往上抛出。 正例： 1logger.error(各类参数或者对象 toString() + "_" + e.getMessage(), e); 【推荐】谨慎地记录日志。生产环境禁止输出 debug日志；有选择地输出 info 日志 ；如果使用 warn 来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑爆，并记得及时删除这些观察日志。 说明：大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点。记录日志时请 思考：这些日志真的有人看吗？看到这条日志你能做什么？能不能给问题排查带来好处？ 【推荐】可以使用 warn 日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适从。如非必要，请不要在此场景打出 error 级别，避免频繁报警。 说明：注意日志输出的级别，error 级别只记录系统逻辑出错、异常或者重要的错误信息。 【推荐】尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用中文描述即可，否则容易产生歧义。国际化团队或海外部署的服务器由于字符集问题，【强制】使用全英文来注释和描述日志错误信息。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>规范</tag>
        <tag>log</tag>
        <tag>异常</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EFK日志系统搭建实践(一)]]></title>
    <url>%2F2019%2F03%2F06%2FEFK%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA%E5%AE%9E%E8%B7%B5(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[一、什么是EFKEFK是ELK的变种，主要是将日志进行聚合，方便查询。EFK不是一个软件，而是一系列工具的组合(一种问题的解决方案)，来解决传统方式查询日志繁琐、低效的问题。EFK是将ELK中的Logstash替换成Filebeat，两者对比如下 对比 优势 劣势 备注 Logstash 灵活度高插件多处理问题范围广 与其他替代品对比性能低资源占用高(默认堆为1GB)不支持缓存 Redis或Kafka作为中心缓存池 Filebeat 资源占用低可靠性高性能高 应用范围小只支持将日志发送到ES、Logstash、redis(5.x)和kafka(5.x)只能简单过滤数据(5.x) 一般选择Kafka作为下游管道如果选择Logstash还是会出现性能和资源消耗问题 二、EFK具体组成E：Elasticsearch - 数据存储、搜索、分析Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。F：Filebeat - 数据搜集K：Kibana - 数据展示最简单的EFK架构图 三、搭建步骤1、ES安装因为ES需要java运行环境（Java 8 及以上），所以先要安装Java 8 下载地址，下载完成后，使用工具上传到服务器1https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk-8u201-linux-x64.tar.gz 解压1tar -zxvf jdk-8u201-linux-x64.tar.gz 修改系统环境变量1vi /etc/profile 在文件末尾加上如下内容12345JAVA_HOME=/usr/java/jdk1.8.0_181/JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 其中JAVA_HOME后面的路径替换为自己jdk的解压路径按下ESC键进入命令行模式，输入以下代码,保存并退出1:wq 让刚刚配置的环境变量生效1source /etc/profile 检验jdk是否安装成功1java -version 出现版本号信息则表示安装成功 下载ES，这里使用的版本为6.6.1，注意ES、Filebeat以及Kibana必须使用相同的版本1wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.1.tar.gz 解压1tar -zxvf elasticsearch-6.6.1.tar.gz 进入ES根目录，修改配置文件1vi config/elasticsearch.yml 修改为以下参数12network.host: 0.0.0.0http.port: 9200 Elasticsearch不能使用root用户打开，所以需要额外的一个用户来启动它1234567adduser elastic#设置密码（需要输入两次）passwd 123456789#设置文件夹权限chmod -R 777 /usr/efk/es/elasticsearch-6.6.1#切换用户su elastic 启动ES1234#前台运行，关闭会话窗口ES会停止./bin/elastcsearch#后台运行./bin/elastcsearch -d 如何关闭ES123ps -ef | grep elastic#找到进程号并杀死,假设这里为1234kill -9 1234 可能会遇到的问题 启动时内存不足 123456Java HotSpot(TM) 64-Bit Server VM warning: INFO: os::commit_memory(0x00000000c5330000, 986513408, 0) failed; error=&apos;Cannot allocate memory&apos; (errno=12)## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 986513408 bytes for committing reserved memory.# An error report file with more information is saved as:# logs/hs_err_pid13544.log 这是因为ES默认的最小内存为1G，如果是测试环境可修改为更小的值，方法如下进入ES根目录，修改配置文件jvm.options 1vi /config/jvm.options 修改以下两个参数到合适的大小，这里我们修改为200m 12-Xms200m-XMX200m 最大文件描述符太低 1max file descriptors [65535] for elasticsearch process is too low, increase to at least [65536] 切换到root用户，修改系统限制配置(limits.conf的作用) 1vi /etc/security/limits.conf 将如下两个配置从65535修改为65536 12* soft nofile 65536 * hard nofile 65536 如果没有这两个配置就在后面加上这两个，按下ESC键，输入以下指令保存并退出 1:wq 最大线程数太低 1max number of threads [3882] for user [elastic] is too low, increase to at least [4096] 切换到root用户方案1、进入limits.d目录下修改配置文件 1vi /etc/security/limits.d/90-nproc.conf 将如下配置从3882修改为5000 12* soft nproc 5000* hard nproc 5000 方案2、如果没有90-nproc.conf此配置文件，那么就在问题2的配置文件后面追加如下配置 1234* soft nproc 5000* hard nproc 5000root soft nproc 5000root hard nproc 5000 最大虚拟内存区域太低 1max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 切换到root用户，修改sysctl.conf配置文件 1vi /etc/sysctl.conf 在文件内容末尾添加如下配置 1vm.max_map_count=262144 按ESC键，输入以下命令保存并退出 1:wq 执行如下命令 1sysctl -p 以上所有配置文件的修改需要root用户权限 解决完所有问题后，启动ES，并输入以下命令验证是否启动成功123456789101112131415161718192021curl 127.0.0.1:9200 ``` 如果出现以下json数据，则表示启动成功```json&#123; &quot;name&quot; : &quot;wL6HMwx&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;FRes2_jQTNydfbLcmEwHfg&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.6.1&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;1fd8f69&quot;, &quot;build_date&quot; : &quot;2019-02-13T17:10:04.160291Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.6.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 2. 安装Kibana下载Kibana1wget https://artifacts.elastic.co/downloads/kibana/kibana-6.6.1-linux-x86_64.tar.gz 进入根目录，修改配置文件1vi config/kabana.yml 修改如下参数1234server.port: 5601server.host: 0.0.0.0elasticsearch.hosts: ["http://localhost:9200"]kibana.index: ".kibana" 保存并退出启动Kibana1234#前台运行./bin/kibana#后台运行nohup ./bin/kibana 如何停止Kibana123fuser -n tcp 5601#找到进程号，杀掉进程，假设这里为5678kill -9 5678 3. 安装Filebeat下载Filebeat1wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.6.1-linux-x86_64.tar.gz 解压1tar -zxvf filebeat-6.6.1-linux-x86_64.tar.gz 进入根目录，修改配置文件1vi filebeat.yml 修改如下几个配置，注意缩进（filebeat处理多行日志） 12345678910111213141516171819202122#=========================== Filebeat inputs =============================filebeat.inputs:- type: log #如果是在windows上运行需要指定字符集，否则中文乱码 #encoding: GB2312 enabled: false paths: - /var/log/*.log - /var/log/*.out #- c:\programdata\elasticsearch\logs\* ### Multiline options #不以YYYY-MM-DD格式开头的全部追加到上一行 multiline.pattern: ^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125; multiline.negate: false multiline.match: after#============================== Kibana =====================================setup.kibana: host: "localhost:5601"#-------------------------- Elasticsearch output ------------------------------output.elasticsearch: hosts: ["localhost:9200"] 启动Filebeat1./filebeat -c /usr/efk/filebeat/filebeat.yml 5. 配置Kibana进入Kibanalocalhost:5601按下图顺序找到配置我们可以看到Filebeat创建的索引格式为filebeat-x.x.x-yyyy.mm.dd这里显示的为filebeat-6.6.1-2019.03.07所以为了匹配这个索引，我们需要在上方输入框输入以下索引匹配格式1filebeat-6.6.1-* 点击Next Step进入下一步配置这里我们选择@timestamp点击Create index pattern，然后进入 Discover面板就能看到Filebeat收集到的日志数据了 6. Kibana安全Ngnix实现Kibana安全认证X-pack实现Kibana安全认证-收费 相关资料ES、Filebeat、Kibana官网Kibana查询语法(Lucene语法)Kibana用户指南Docker中使用FilebeatDocker中使用ESDocker中使用KibanaK8s中使用Filebeat修改Filebeat默认ES索引]]></content>
      <categories>
        <category>EFK</category>
      </categories>
      <tags>
        <tag>EFK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EFK日志系统搭建实践(二)]]></title>
    <url>%2F2019%2F03%2F06%2FEFK%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA%E5%AE%9E%E8%B7%B5(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[上一篇文章中，我们搭建了一套最简单的EFK系统。但是收集到的数据都是作为一个整体直接写入ES，这样不利于日志的管理、查询和分析。我们希望按照日志的格式来提取相关信息（时间、日志等级、产生日志的类信息等）格式化后再存入ES。所以在原有的基础上加入Logstash（与之前ES和Filebeat版本保持一致，这里使用的版本是6.6.1）来满足我们的这个需求。日志系统拓扑结构如下 一、搭建步骤1、Logstash安装下载1wget https://artifacts.elastic.co/downloads/logstash/logstash-6.6.1.tar.gz 解压1tar -zxvf logstash-6.6.1.tar.gz 修改配置文件1vi /config/logstash-sample.conf 将配置修改为如下格式123456789101112131415161718192021222324252627# Sample Logstash configuration for creating a simple# Beats -&gt; Logstash -&gt; Elasticsearch pipeline.input &#123; beats &#123; port =&gt; 5044 &#125;&#125;#grok的基本语法：key用“&lt;&gt;”包围，并在前面加上“?”，value则使用正则来表示，#grok在线调试http://grokdebug.herokuapp.com/，或者使用Kibana=》Dev Tools=》Grok Debuggerfilter &#123; grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;(?&lt;date&gt;\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;\s(?&lt;datetime&gt;%&#123;TIME&#125;))\s(?&lt;level&gt;[A-Z]&#123;4,&#125;)\s+(?&lt;class&gt;[A-Za-z0-9/.]&#123;4,&#125;)\s-\s(?&lt;msg&gt;.*)(\n(?&lt;moreInfo&gt;[\s\S]*))?&quot; &#125; overwrite =&gt; [&quot;message&quot;] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;http://localhost:9200&quot;] index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; user =&gt; &quot;user&quot; password =&gt; &quot;password&quot; &#125;&#125; 上述配置解析的日志格式如下(如有新日志格式，需要重新编写过滤表达式)123456789#格式一2019-03-12 14:31:05,545 INFO com.njbd.jay.controller.System.ManagerController - 公钥模:10001#格式二2019-01-28 10:35:39,745 ERROR com.njbd.jay.exception.GlobalExceptionHandler - serverError:更新话题失败com.njbd.jay.exception.ServerRunTimeException: 更新话题失败 at com.njbd.jay.service.Impl.TopicServiceImpl.updateTopic(TopicServiceImpl.java:331) ~[classes/:na] ...#格式三2019-03-19 11:16:31,024 INFO [InvoiceOrderCancelJob.java:52] com.njbd.jay.job.InvoiceOrderCancelJob - InvoiceOrderCancelJob.execute.finish 启动Logstash1.\bin\logstash -f .\config\logstash-sample.conf 2、修改Filebeat输出将Filebeat输出修改到Logstash1234#----------------------------- Logstash output --------------------------------output.logstash: # The Logstash hosts hosts: ["localhost:5044"] 启动Filebeat 相关资料Logstash过滤文章Docker中使用Logstash]]></content>
      <categories>
        <category>EFK</category>
      </categories>
      <tags>
        <tag>EFK</tag>
        <tag>logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css笔记]]></title>
    <url>%2F2019%2F02%2F27%2Fcss%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[快速导航1、隐藏滚动条2、div居中3、元素动画(左右移动)4、选中元素内指定子元素5、颜色渐变 1、隐藏滚动条1234567891011121314.inner-container &#123; position: absolute; left: 0; top: 0; bottom: 60px; overflow-x: hidden; overflow-y: scroll; scrollbar-width: none;&#125;/* for Chrome 只针对谷歌浏览器*/.inner-container::-webkit-scrollbar &#123; display: none;&#125; 2、div居中1234#testDiv &#123; width: 300px; margin: 0 auto; &#125; 3、元素动画(左右移动)12345678910111213141516#enterLeft &#123; position: relative; -webkit-animation: moveLeft 0.6s infinite alternate; animation: moveLeft 0.6s infinite alternate; &#125;@-webkit-keyframes moveLeft &#123; 0% &#123; left: 0px; &#125; 100% &#123; left: -10px; &#125; &#125;@keyframes moveLeft &#123; 0% &#123; left: 0px; &#125; 100% &#123; left: -10px; &#125; &#125; 4、选中元素内指定子元素12345678/* 第一个li */ #testDiv &gt; li:first-child&#123;&#125; /* 最后一个li */#testDiv &gt; li:last-child&#123;&#125; /* 第五个 */#testDiv &gt; li:nth-child(5)&#123;&#125; 5、颜色渐变12345678910111213141516171819202122232425262728293031323334353637383940414243/* 双色 *//* 方向可以是 left、right、bottom left等等 *//* 也可以指定角度 90deg */#testDiv1 &#123; width: 500px; height: 2.5px; float: left; background: -webkit-linear-gradient(left, rgba(198, 198, 198, 0), rgba(198, 198, 198, 1)); /* Safari 5.1 - 6.0 */ background: -o-linear-gradient(right, rgba(198, 198, 198, 0), rgba(198, 198, 198, 1)); /* Opera 11.1 - 12.0 */ background: -moz-linear-gradient(right, rgba(198, 198, 198, 0), rgba(198, 198, 198, 1)); /* Firefox 3.6 - 15 */ background: linear-gradient(to right, rgba(198, 198, 198, 0), rgba(198, 198, 198, 1)); /* 标准的语法（必须放在最后） */&#125;/* 3种颜色均匀分布 */#testDiv2 &#123; height: 200px; background: -webkit-linear-gradient(red, green, blue); /* Safari 5.1 - 6.0 */ background: -o-linear-gradient(red, green, blue); /* Opera 11.1 - 12.0 */ background: -moz-linear-gradient(red, green, blue); /* Firefox 3.6 - 15 */ background: linear-gradient(red, green, blue); /* 标准的语法（必须放在最后） */&#125;/* 7种颜色均匀分布 */#testDiv3 &#123; height: 200px; background: -webkit-linear-gradient(red, orange, yellow, green, blue, indigo, violet); /* Safari 5.1 - 6.0 */ background: -o-linear-gradient(red, orange, yellow, green, blue, indigo, violet); /* Opera 11.1 - 12.0 */ background: -moz-linear-gradient(red, orange, yellow, green, blue, indigo, violet); /* Firefox 3.6 - 15 */ background: linear-gradient(red, orange, yellow, green, blue, indigo, violet); /* 标准的语法（必须放在最后） */&#125;/* 颜色分布指定比例 */#testDiv4 &#123; height: 200px; background: -webkit-linear-gradient(red 10%, yellow 50%, blue 90%); /* Safari 5.1 - 6.0 */ background: -o-linear-gradient(red 10%, yellow 50%, blue 90%); /* Opera 11.1 - 12.0 */ background: -moz-linear-gradient(red 10%, yellow 50%, blue 90%); /* Firefox 3.6 - 15 */ background: linear-gradient(red 10%, yellow 50%, blue 90%); /* 标准的语法（必须放在最后） */&#125;]]></content>
      <categories>
        <category>css</category>
      </categories>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jquery笔记]]></title>
    <url>%2F2019%2F02%2F27%2Fjquery%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[快速导航1、监听浏览器窗口变化2、添加\移除class3、设置css 1、监听浏览器窗口变化12345678910111213$(window).resize(function () &#123; //当浏览器大小变化时 //浏览器时下窗口可视区域高度 console.log($(window).height()); //浏览器时下窗口文档的高度 console.log($(document).height()); //浏览器时下窗口文档body的高度 console.log($(document.body).height()); //浏览器时下窗口文档body的总高度 包括border padding margin console.log($(document.body).outerHeight(true)); &#125;); 2、添加\移除class12$("#test").addClass("testClass");$("#test").removeClass("testClass"); 3、设置css1$("#testDiv").css("height", 100);]]></content>
      <categories>
        <category>jquery</category>
      </categories>
      <tags>
        <tag>jquery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客搭建日志]]></title>
    <url>%2F2019%2F01%2F08%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[一、按照教程完成基础搭建博主使用的教程安装: hexo + github 搭建个人博客日常维护维护: 使用hexo，如果换了电脑怎么更新博客？ 二、next配置配置文件介绍]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
